## Introduction

Over the years, we have seen how decision making and analytics in many industries are increasingly being driven by data and models. Many organizations are starting to embrace the use of machine learning as part of business optimization. However, machine learning models are only as good as the quality of data used to train them. We could consider how financial institutions use client information such as transaction amounts or locations to detect credit card fraud, having unclean data on these observations can easily throw off a machine learning model. So once data is collected from various sources, the first thing is to ensure that the data is cleaned appropriately before being feed into a model.

Data preprocessing is never an easy step and many data scientists face several challenges when it comes to data preprocessing. Aside from the challenge of understanding the business problem and trying to come up with the best approach to solving it, data preprocessing is also an area that requires a lot of time and input. In this article, I used the scientific Python ecosystem and geospatial data visualization & analysis capabilities of Folium and the ArcGIS platform to highlight some of the key approaches to data preprocessing, namely; Data cleaning, Exploratory data analysis, variable transformation and feature engineering.

I used the Chicago housing data obtained from [Github](https://github.com/ageron/handson-ml2/tree/master/datasets/housing). The data set contains 20640 entries. Each entry represents one district. There are 10 attributes longitude, latitude, housing_median_age, total_rooms, total_bed rooms, population, households, median_income, median_house_value, and ocean_proximity. This dataset was based on data from the 1990 California census. It is not exactly recent, but it has many qualities for learning, so we will pretend it is recent data.
